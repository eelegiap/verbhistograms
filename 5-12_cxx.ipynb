{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the RNC to look at preps in certain windows of verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/paigelee/Desktop/spring2021/clancy/verbhistograms'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98892"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from corus import load_morphoru_rnc\n",
    "\n",
    "path = 'RNCgoldInUD_Morpho.conll'\n",
    "records = load_morphoru_rnc(path)\n",
    "rnccorpus = []\n",
    "for record in records:\n",
    "    rnccorpus.append(record)\n",
    "len(rnccorpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### looking at collocations around verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MorphoToken(\n",
       "    text='.',\n",
       "    lemma='.',\n",
       "    pos='PUNCT',\n",
       "    feats={},\n",
       "    feats2={}\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(random.choice(rnccorpus).tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All cxx (not just verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing 2 ...\n",
      "parsing 3 ...\n",
      "parsing 4 ...\n",
      "parsing 5 ...\n",
      "parsing 6 ...\n"
     ]
    }
   ],
   "source": [
    "def build_sentence(tokens):\n",
    "    sentence = ''\n",
    "    for i, token in enumerate(tokens):\n",
    "        text = token.text\n",
    "        space = ' '\n",
    "        if token.pos == 'PUNCT':\n",
    "            space = ''\n",
    "        if text == None:\n",
    "            text = ''\n",
    "        sentence = sentence + space + text\n",
    "    return sentence.strip()\n",
    "\n",
    "# sample = random.sample(rnccorpus,1000)\n",
    "sample = rnccorpus\n",
    "windowDict = dict()\n",
    "for window in range(2, 7):\n",
    "    print('parsing',window,'...')\n",
    "#     windowDict[window]= dict()\n",
    "    for sent in sample:\n",
    "        currentindex = -1\n",
    "        for token in sent.tokens:\n",
    "            currentindex += 1\n",
    "            lemma = token.lemma\n",
    "            nonalphasent = False\n",
    "            propernounfound = False\n",
    "            windowstart = currentindex\n",
    "            # check window\n",
    "            windowend = currentindex + window\n",
    "            if windowend < len(sent.tokens):\n",
    "                # get rid of proper nouns\n",
    "                try:\n",
    "                    for windowtok in sent.tokens[windowstart:windowend]:\n",
    "                        if windowtok.feats2['NameType'] in ['Giv','Sur']:\n",
    "                            propernounfound = True\n",
    "                    if propernounfound:\n",
    "                        break\n",
    "                except:\n",
    "                    propernounfound = False\n",
    "                thissent = build_sentence(sent.tokens[windowstart:windowend])\n",
    "                cxkey = thissent.lower()\n",
    "                if '/' in cxkey or cxkey[-1] == ',' or cxkey[-2:] == '--' or cxkey[:2] == '--':\n",
    "                    break\n",
    "                alphacount = 0\n",
    "                punctorspacecount = 0\n",
    "                uppercount = 0\n",
    "                for char in thissent:\n",
    "                    if char.isnumeric():\n",
    "                        nonalphasent = True\n",
    "                    if char.isalpha():\n",
    "                        alphacount += 1\n",
    "                    if char in string.punctuation or char == ' ':\n",
    "                        punctorspacecount += 1\n",
    "                    if char.isupper():\n",
    "                        uppercount += 1\n",
    "                if uppercount == alphacount:\n",
    "                    break\n",
    "                if nonalphasent:\n",
    "                    break\n",
    "                if alphacount == 1:\n",
    "                    break\n",
    "                if punctorspacecount == len(thissent):\n",
    "                    break\n",
    "                windowDict.setdefault(cxkey, dict())\n",
    "                windowDict[cxkey].setdefault('counts',0)\n",
    "                windowDict[cxkey].setdefault('sents', [])\n",
    "                windowDict[cxkey]['counts'] += 1\n",
    "                windowDict[cxkey]['sents'].append(build_sentence(sent.tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countdict = dict()\n",
    "# for window in windowDict:\n",
    "#     countdict[window] = []\n",
    "#     for cxkey in windowDict[window]:\n",
    "#         count = windowDict[window][cxkey]['counts']\n",
    "#         countdict[window].append((count, cxkey))\n",
    "# print('construction counts:')\n",
    "# for wind in countdict:\n",
    "#     print(wind, len(countdict[wind]))\n",
    "# print()\n",
    "# sortedcountdict = dict()\n",
    "# for window in countdict:\n",
    "#     sortedcountlist = sorted(countdict[window], reverse=True)\n",
    "#     sortedcountdict[window] = sortedcountlist\n",
    "# print('keys are...')\n",
    "# sortedcountdict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130920\n",
      "['латиноамериканской породы каудильо', 'всё чаще приходит', 'рынке интернет-рекламы доминируют', 'на другой день', 'вернуть хотя бы малые']\n"
     ]
    }
   ],
   "source": [
    "cxx = list(windowDict.keys())\n",
    "print(len(cxx))\n",
    "print(random.sample(cxx, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cxlist = []\n",
    "for cx in windowDict:\n",
    "    count = windowDict[cx]['counts']\n",
    "    if count == 1:\n",
    "        continue\n",
    "    else:\n",
    "        cxlist.append((count, cx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41280"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cxlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedcxlist = sorted(cxlist, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sortedcxlist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a3c6fd1874b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msortedcxlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sortedcxlist' is not defined"
     ]
    }
   ],
   "source": [
    "sortedcxlist[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting constructions onto pca graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cxx beginning with verbs only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing 2 ...\n",
      "parsing 3 ...\n",
      "parsing 4 ...\n",
      "parsing 5 ...\n",
      "parsing 6 ...\n"
     ]
    }
   ],
   "source": [
    "def build_sentence(tokens):\n",
    "    sentence = ''\n",
    "    for i, token in enumerate(tokens):\n",
    "        text = token.text\n",
    "        space = ' '\n",
    "        if token.pos == 'PUNCT':\n",
    "            space = ''\n",
    "        if text == None:\n",
    "            text = ''\n",
    "        sentence = sentence + space + text\n",
    "    return sentence.strip()\n",
    "\n",
    "# sample = random.sample(rnccorpus,1000)\n",
    "sample = rnccorpus\n",
    "windowDict = dict()\n",
    "for window in range(2, 7):\n",
    "    print('parsing',window,'...')\n",
    "    windowDict[window]= dict()\n",
    "    for sent in sample:\n",
    "        currentindex = -1\n",
    "        for token in sent.tokens:\n",
    "            currentindex += 1\n",
    "            if token.pos == 'VERB':\n",
    "                verblemma = token.lemma\n",
    "                windowstart = currentindex\n",
    "                # check window\n",
    "                windowend = currentindex + window\n",
    "                if windowend < len(sent.tokens):\n",
    "                    thissent = build_sentence(sent.tokens[windowstart:windowend])\n",
    "                    cxkey = thissent.lower()\n",
    "                    if '/' in cxkey or cxkey[-1] == ',' or cxkey[-2:] == '--':\n",
    "                        break\n",
    "                    windowDict[window].setdefault(cxkey, dict())\n",
    "                    windowDict[window][cxkey].setdefault('counts',0)\n",
    "                    windowDict[window][cxkey].setdefault('sents', [])\n",
    "                    windowDict[window][cxkey]['counts'] += 1\n",
    "                    windowDict[window][cxkey]['sents'].append(build_sentence(sent.tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "countlist = []\n",
    "for window in windowDict:\n",
    "    for cxkey in windowDict[window]:\n",
    "        count = windowDict[window][cxkey]['counts']\n",
    "        countlist.append((count, cxkey))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328466"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(countlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedcountlist = sorted(countlist, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(627, 'может быть'),\n",
       " (145, 'было бы'),\n",
       " (135, 'е.'),\n",
       " (85, 'сказать, что'),\n",
       " (81, 'могут быть'),\n",
       " (80, 'говорить о'),\n",
       " (68, 'сказал, что'),\n",
       " (65, 'см.'),\n",
       " (65, 'думаю, что'),\n",
       " (62, 'хотелось бы'),\n",
       " (59, 'хотел бы'),\n",
       " (59, 'см.:'),\n",
       " (57, 'был в'),\n",
       " (56, 'было в'),\n",
       " (54, 'сказал он'),\n",
       " (53, 'кажется, что'),\n",
       " (51, 'зависит от'),\n",
       " (51, 'есть и'),\n",
       " (49, 'знаю, что'),\n",
       " (49, 'есть у'),\n",
       " (49, 'есть в'),\n",
       " (48, 'состоит в'),\n",
       " (48, 'представляет собой'),\n",
       " (47, 'хочу сказать'),\n",
       " (47, 'могу сказать'),\n",
       " (43, 'идёт о'),\n",
       " (41, 'считаю, что'),\n",
       " (41, 'понял, что'),\n",
       " (41, 'есть ли'),\n",
       " (40, 'оказалось, что'),\n",
       " (40, 'могли бы'),\n",
       " (39, 'казалось, что'),\n",
       " (39, 'заключается в'),\n",
       " (39, 'говорим о'),\n",
       " (39, 'выяснилось, что'),\n",
       " (39, 'было не'),\n",
       " (38, 'смотрит на'),\n",
       " (38, 'была в'),\n",
       " (37, 'сказал я'),\n",
       " (37, 'начиная с'),\n",
       " (37, 'имею в'),\n",
       " (37, 'говорят, что'),\n",
       " (36, 'относится к'),\n",
       " (36, 'было и'),\n",
       " (35, 'считают, что'),\n",
       " (35, 'казалось бы'),\n",
       " (35, 'имею в виду'),\n",
       " (35, 'был бы'),\n",
       " (34, 'спросил я'),\n",
       " (34, 'состоит в том'),\n",
       " (34, 'исходя из'),\n",
       " (34, 'говорит, что'),\n",
       " (33, 'называется\"'),\n",
       " (33, 'мог бы'),\n",
       " (33, 'есть ещё'),\n",
       " (32, 'сказала, что'),\n",
       " (32, 'сказал андрей'),\n",
       " (32, 'находится в'),\n",
       " (32, 'знал, что'),\n",
       " (32, 'были в'),\n",
       " (30, 'состоит из'),\n",
       " (30, 'приводит к'),\n",
       " (29, 'состоит в том, что'),\n",
       " (29, 'говорит о'),\n",
       " (28, 'посмотрел на'),\n",
       " (28, 'значит, что'),\n",
       " (28, 'быть не'),\n",
       " (27, 'считает, что'),\n",
       " (26, 'показывает, что'),\n",
       " (26, 'был не'),\n",
       " (25, 'свидетельствует о'),\n",
       " (25, 'говорят о'),\n",
       " (25, 'говорят все'),\n",
       " (24, 'означает, что'),\n",
       " (24, 'есть это'),\n",
       " (24, 'есть на'),\n",
       " (24, 'быть в'),\n",
       " (24, 'было так'),\n",
       " (24, 'было очень'),\n",
       " (24, 'был такой'),\n",
       " (23, 'относятся к'),\n",
       " (23, 'отметить, что'),\n",
       " (23, 'ответить на'),\n",
       " (23, 'заявил, что'),\n",
       " (23, 'глядя на'),\n",
       " (22, 'спросил он'),\n",
       " (22, 'смотрел на'),\n",
       " (22, 'представить себе'),\n",
       " (22, 'показали, что'),\n",
       " (22, 'находятся в'),\n",
       " (22, 'быть может'),\n",
       " (21, 'смотреть на'),\n",
       " (21, 'сказали, что'),\n",
       " (21, 'сказала я'),\n",
       " (21, 'понимаю, что'),\n",
       " (21, 'могла бы'),\n",
       " (21, 'знала, что'),\n",
       " (21, 'есть вы'),\n",
       " (21, 'было хорошо'),\n",
       " (20, 'хотели бы')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortedcountlist[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep + case!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window size of -3 complete...\n",
      "window size of -2 complete...\n",
      "window size of -1 complete...\n",
      "window size of 0 complete...\n",
      "window size of 1 complete...\n",
      "window size of 2 complete...\n",
      "window size of 3 complete...\n"
     ]
    }
   ],
   "source": [
    "def build_sentence(tokens, currentindex, adpindex, caseindex):\n",
    "    sentence = ''\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token.pos == 'PUNCT':\n",
    "            space = ''\n",
    "        else:\n",
    "            space = ' '\n",
    "        if i in [currentindex, adpindex, caseindex]:\n",
    "            text = token.text.upper()\n",
    "        else:\n",
    "            text = token.text\n",
    "        if text == None:\n",
    "            text = ''\n",
    "        sentence = sentence + space + text\n",
    "    return sentence.strip()\n",
    "\n",
    "# sample = random.sample(rnccorpus,100)\n",
    "sample = rnccorpus\n",
    "windowList = []\n",
    "for window in range(-3, 4):\n",
    "    dataDict = dict()\n",
    "    for sent in sample:\n",
    "        currentindex = 0\n",
    "        for token in sent.tokens:\n",
    "            if token.pos == 'VERB':\n",
    "                verblemma = token.lemma\n",
    "#                 if verblemma not in okayverbs:\n",
    "#                     break\n",
    "                if verblemma not in dataDict:\n",
    "                    dataDict[verblemma] = dict()\n",
    "                    dataDict[verblemma]['counts'] = dict()\n",
    "                    dataDict[verblemma]['sentences'] = dict()\n",
    "                adpindex = currentindex + window\n",
    "                if adpindex >= 0 and adpindex < len(sent.tokens):\n",
    "                    adptoken = sent.tokens[adpindex]\n",
    "                    if adptoken.pos == 'PUNCT' and adpindex + 1 >= 0 and adpindex + 1 < len(sent.tokens):\n",
    "                        adpindex = adpindex + 1\n",
    "                    if adptoken.pos == 'ADP':\n",
    "                        adplemma = adptoken.lemma\n",
    "                        caseindex = adpindex + 1\n",
    "    \n",
    "                        if caseindex >= 0 and caseindex < len(sent.tokens):\n",
    "                            casetoken = sent.tokens[caseindex]\n",
    "                            if casetoken.pos == 'PUNCT' and caseindex + 1 >= 0 and caseindex + 1 < len(sent.tokens):\n",
    "                                caseindex = caseindex + 1\n",
    "                            casetoken = sent.tokens[caseindex]\n",
    "                            try:\n",
    "                                case = casetoken.feats['Case']\n",
    "                                if case == 'Ins':\n",
    "                                    case = 'Inst'\n",
    "                                adpandcase = adplemma + ' + ' + case.upper()\n",
    "                            except:\n",
    "                                break\n",
    "                                \n",
    "                    else:\n",
    "                        if window in [-1,1]:\n",
    "                            # not an adposition directly before or after verb\n",
    "                            try: \n",
    "                                if adpindex - 1 >= 0:\n",
    "                                    # need to make sure prev token is not adp\n",
    "                                    if sent.tokens[adpindex - 1].pos != 'ADP':\n",
    "                                        case = adptoken.feats['Case']\n",
    "                                        if case == 'Ins':\n",
    "                                            case = 'Inst'\n",
    "                                        adpandcase = 'No prep + ' + case.upper()\n",
    "                                        caseindex = currentindex\n",
    "                            except:\n",
    "                                break\n",
    "                        else:\n",
    "                            break\n",
    "                            \n",
    "                    if adpandcase not in dataDict[verblemma]['counts']:                               \n",
    "                        dataDict[verblemma]['counts'][adpandcase] = 0\n",
    "                        dataDict[verblemma]['sentences'][adpandcase] = []\n",
    "\n",
    "                    dataDict[verblemma]['counts'][adpandcase] += 1\n",
    "                    formattedsent = build_sentence(sent.tokens, currentindex, adpindex, caseindex)\n",
    "                    if formattedsent not in dataDict[verblemma]['sentences'][adpandcase]:\n",
    "                        dataDict[verblemma]['sentences'][adpandcase].append(formattedsent)\n",
    "                                \n",
    "                    \n",
    "            currentindex += 1\n",
    "    print(f'window size of {window} complete...')\n",
    "    windowList.append(dataDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ОБЯЗАТЕЛЬНО СХОЖУ.',\n",
       " 'А когда первый РАЗ СХОДИЛА в кино и увидела музыкантов, которые играют в фойе, мне стало жаль моего бедного дедушку: зрители переговаривались, жевали бутерброды, шуршали газетами, а старые люди на сцене играли вальс.',\n",
       " 'В ПЛАЦКАРТУ СХОДИ, там быстро развеешься.',\n",
       " 'Наш корреспондент Микаэль Укин получил ЗАДАНИЕ СХОДИТЬ в Мавзолей.',\n",
       " 'Там учителя с УМА СХОДЯТ, не ПОЙМУТ, откуда такое взялось.',\n",
       " 'Я ему полис ОТДАЛА/ пусть там на РАБОТЕ СХОДИТ...',\n",
       " 'СЕЙЧАС СХОЖУ/ ГОВОРИТ/ завтра/ говорит/ этот/ паспорт заберу...',\n",
       " 'Я этот рубль БЕРЕГУ/ то в КИНО СХОДИТЬ/ то в кафе сходить/ куда-нибудь.',\n",
       " 'Я этот рубль БЕРЕГУ/ то в кино сходить/ то в КАФЕ СХОДИТЬ/ куда-нибудь.']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windowList[2]['сходить']['sentences']['No prep + ACC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "# removing uncommon verbs (<10 occurrences)\n",
    "uncommonVerbs = set()\n",
    "totalcount = dict()\n",
    "for windowDict in windowList:\n",
    "    for verb in windowDict:\n",
    "        if verb not in totalcount:\n",
    "            totalcount[verb] = 0\n",
    "        countDict = windowDict[verb]['counts']\n",
    "        for prep in windowDict[verb]['counts']:\n",
    "            totalcount[verb] += windowDict[verb]['counts'][prep]\n",
    "for verb in totalcount:\n",
    "    if totalcount[verb] < 30:\n",
    "        uncommonVerbs.add(verb)\n",
    "print(len(uncommonVerbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for verbtoremove in uncommonVerbs:\n",
    "    for windowDict in windowList:\n",
    "        try:\n",
    "            del windowDict[verbtoremove]\n",
    "        except:\n",
    "            False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "597"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(windowList[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'в + LOC': 4,\n",
       " 'среди + GEN': 1,\n",
       " 'на + LOC': 1,\n",
       " 'с + INST': 2,\n",
       " 'из + GEN': 1,\n",
       " 'после + GEN': 1,\n",
       " 'по + DAT': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windowList[1]['читать']['counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/paigelee/Desktop/spring2021/clancy/verbhistograms\n"
     ]
    }
   ],
   "source": [
    "cd verbhistograms/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcxlabels = set()\n",
    "for windowDict in windowList:\n",
    "    for verb in windowDict:\n",
    "        countdict = windowDict[verb]['counts']\n",
    "        for cxlabel in countdict:\n",
    "            allcxlabels.add(cxlabel)\n",
    "allcxlabels = list(allcxlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting rid of cxx with count < 10\n",
    "totalcxcounts = dict()\n",
    "for windowDict in windowList:\n",
    "    for verb in windowDict:\n",
    "        countdict = windowDict[verb]['counts']\n",
    "        for cx in countdict:\n",
    "            if cx not in totalcxcounts:\n",
    "                totalcxcounts[cx] = 0\n",
    "            totalcxcounts[cx] += 1\n",
    "lst = []\n",
    "for cx in totalcxcounts:\n",
    "    lst.append((totalcxcounts[cx],cx))\n",
    "i = 0\n",
    "greaterthan10cx = []\n",
    "for ct, cx in lst:\n",
    "    if ct > 10:\n",
    "        greaterthan10cx.append(cx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verb, windowsize, prep1, prep2, prep3, prep4, prep5...\n",
    "rows = []\n",
    "# cxused = allcxlabels\n",
    "cxused = greaterthan10cx\n",
    "for windowIndex, windowDict in enumerate(windowList):\n",
    "    windowSize = windowIndex - 3\n",
    "    for verb in windowDict:\n",
    "        countdict = windowDict[verb]['counts']\n",
    "        csvline = [verb, windowSize]\n",
    "        for cxlabel in cxused:\n",
    "            if cxlabel in countdict:\n",
    "                count = countdict[cxlabel]\n",
    "            else:\n",
    "                count = 0\n",
    "            csvline.append(count)\n",
    "        rows.append(csvline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['встретиться', -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 0, 2, 2, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "r = random.choice(rows)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['Verb','WindowSize']\n",
    "\n",
    "for cxlabel in greaterthan10cx:\n",
    "    fields.append(cxlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/paigelee/Desktop/spring2021/clancy/verbhistograms'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# writing to csv file \n",
    "filename = 'csvdata.csv'\n",
    "with open(filename, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile) \n",
    "        \n",
    "    # writing the fields \n",
    "    csvwriter.writerow(fields) \n",
    "        \n",
    "    # writing the data rows \n",
    "    csvwriter.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/paigelee/Desktop/spring2021/clancy/verbhistograms\n"
     ]
    }
   ],
   "source": [
    "cd verbhistograms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceDict = dict()\n",
    "windowSize = -3\n",
    "for windowDict in windowList:\n",
    "    sentenceDict[windowSize] = dict()\n",
    "    for verb in windowDict:\n",
    "        sentenceDict[windowSize][verb] = dict()\n",
    "        for cx in windowDict[verb]['sentences']:\n",
    "            sentenceDict[windowSize][verb][cx] = windowDict[verb]['sentences'][cx][:10]\n",
    "    windowSize += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82232\n"
     ]
    }
   ],
   "source": [
    "totalsents = 0\n",
    "for windowDict in windowList:\n",
    "    for verb in windowDict:\n",
    "        for prep in windowDict[verb]['sentences']:\n",
    "            totalsents += len(windowDict[verb]['sentences'][prep])\n",
    "print(totalsents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbDict = dict()\n",
    "\n",
    "for verb in windowList[0]:\n",
    "    verbDict[verb] = dict()\n",
    "windowSize = -3\n",
    "for windowDict in windowList:\n",
    "    for verb in windowDict:\n",
    "        verbDict[verb][windowSize] = dict()\n",
    "        for cx in windowDict[verb]['sentences']:\n",
    "            verbDict[verb][windowSize][cx] = list()\n",
    "            for sent in windowDict[verb]['sentences'][cx]:\n",
    "                verbDict[verb][windowSize][cx].append(sent)\n",
    "    windowSize += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['No prep + DAT', 'No prep + ACC', 'No prep + NOM', 'No prep + INST'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbDict['помочь'][1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/paigelee/Desktop/spring2021/clancy/verbhistograms'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "for verb in verbDict:\n",
    "    with open(f'data/{verb}.json', 'w', encoding='utf8') as jsonfile:\n",
    "        json.dump(verbDict[verb], jsonfile, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write sentence dictionary to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences.json written successfully.\n"
     ]
    }
   ],
   "source": [
    "# writing dictionary to json\n",
    "\n",
    "import json\n",
    "\n",
    "filepath = 'sentences.json'\n",
    "\n",
    "with open(filepath, 'w', encoding='utf8') as json_file:\n",
    "    json.dump(windowList, json_file, ensure_ascii=False)\n",
    "    \n",
    "print(filepath,'written successfully.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
